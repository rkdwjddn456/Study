{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JwYVh31MLcB",
        "outputId": "2b6e1343-cb78-4deb-987d-f81b1fa712f5"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K40OqKrQMnit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980633a2-ab41-464e-9b9c-261013c14c84"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "##%reload_ext nvcc_plugin"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-72a1u9l4\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-72a1u9l4\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=637d639a499674e97e5d36958a5fb5de85ba33143fd2b23a8c0da0e66f5cae37\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-smj_rx19/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9z8lb9bNj5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f314e3bb-d9da-4028-d24c-e3edfa647cd7"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void cuda_hello()\n",
        "{\n",
        "    printf(\"hello world from gpu\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cuda_hello<<<1,5>>>();\n",
        "    cudaDeviceSynchronize(); // sync required in colab enviroment\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world from gpu\n",
            "hello world from gpu\n",
            "hello world from gpu\n",
            "hello world from gpu\n",
            "hello world from gpu\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6riE74DPRacp"
      },
      "source": [
        "Simple Memcpy Scenario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anARF-AeOxm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f0c656-8d80-41c4-bf75-922a22e1abe0"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void addKernel(int *c , const int *a, const int *b)\n",
        "{\n",
        "    int i = threadIdx.x;\n",
        "    c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int SIZE = 5;\n",
        "    const int a[SIZE] = {1,2,3,4,5};\n",
        "    const int b[SIZE] = {10,20,30,40,50};\n",
        " \n",
        "    int c[SIZE] = {0};\n",
        " \n",
        "    int *dev_a = 0;\n",
        "    int *dev_b = 0;\n",
        "    int *dev_c = 0;\n",
        " \n",
        "    cudaMalloc((void**)&dev_a, SIZE * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, SIZE * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, SIZE * sizeof(int));\n",
        " \n",
        "    cudaMemcpy(dev_a, a, SIZE * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, SIZE * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_c, c, SIZE * sizeof(int), cudaMemcpyHostToDevice);\n",
        " \n",
        "    addKernel<<<1,SIZE>>>(dev_c, dev_a, dev_b);\n",
        "    cudaDeviceSynchronize(); // sync required in colab enviroment\n",
        " \n",
        "    cudaMemcpy(c, dev_c, SIZE * sizeof(int), cudaMemcpyDeviceToHost);\n",
        " \n",
        "    printf(\"{1,2,3,4,5} + {10,20,30,40,50} = {%d, %d, %d, %d, %d}\\n\",c[0],c[1],c[2], c[3],c[4]);\n",
        " \n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1,2,3,4,5} + {10,20,30,40,50} = {11, 22, 33, 44, 55}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOo76XnR-eOc"
      },
      "source": [
        "Kernel with 2D Indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJOTsJWjUpU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0311f5a-b86f-4231-de0c-4e4ba7e1ab67"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void kernel(int *a, int dimx, int dimy)\n",
        "{\n",
        "    int ix = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int iy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int idx = iy * dimx + ix;\n",
        "\n",
        "    a[idx] = idx + 1;\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int dimx = 8;\n",
        "    int dimy = 8;\n",
        "\n",
        "    int num_bytes = dimx*dimy*sizeof(int);\n",
        "\n",
        "    int *dev_a;\n",
        "    int *a; \n",
        "\n",
        "    a = (int*)malloc(num_bytes);\n",
        "    cudaMalloc((void**)&dev_a,num_bytes);\n",
        "\n",
        "    cudaMemset(dev_a, 0, num_bytes);\n",
        "\n",
        "    dim3 DimGrid(4,4); // # of blocks in grid = 4 x 4 = 16\n",
        "    dim3 DimBlock(2,2); // # of threads in a blcok = 2 x 2 = 4\n",
        "\n",
        "    kernel<<<DimGrid,DimBlock>>>(dev_a, dimx, dimy);\n",
        "\n",
        "    cudaMemcpy(a, dev_a, num_bytes, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    for(int row=0; row<dimy; row++)\n",
        "    {\n",
        "        for (int col=0; col<dimx; col++)\n",
        "        {\n",
        "            printf(\"(%d,%d)  %d\\t\", col, row, a[row*dimx+col]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    free(a);\n",
        "    cudaFree(dev_a);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0,0)  1\t(1,0)  2\t(2,0)  3\t(3,0)  4\t(4,0)  5\t(5,0)  6\t(6,0)  7\t(7,0)  8\t\n",
            "(0,1)  9\t(1,1)  10\t(2,1)  11\t(3,1)  12\t(4,1)  13\t(5,1)  14\t(6,1)  15\t(7,1)  16\t\n",
            "(0,2)  17\t(1,2)  18\t(2,2)  19\t(3,2)  20\t(4,2)  21\t(5,2)  22\t(6,2)  23\t(7,2)  24\t\n",
            "(0,3)  25\t(1,3)  26\t(2,3)  27\t(3,3)  28\t(4,3)  29\t(5,3)  30\t(6,3)  31\t(7,3)  32\t\n",
            "(0,4)  33\t(1,4)  34\t(2,4)  35\t(3,4)  36\t(4,4)  37\t(5,4)  38\t(6,4)  39\t(7,4)  40\t\n",
            "(0,5)  41\t(1,5)  42\t(2,5)  43\t(3,5)  44\t(4,5)  45\t(5,5)  46\t(6,5)  47\t(7,5)  48\t\n",
            "(0,6)  49\t(1,6)  50\t(2,6)  51\t(3,6)  52\t(4,6)  53\t(5,6)  54\t(6,6)  55\t(7,6)  56\t\n",
            "(0,7)  57\t(1,7)  58\t(2,7)  59\t(3,7)  60\t(4,7)  61\t(5,7)  62\t(6,7)  63\t(7,7)  64\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4koaxd4K9wkD"
      },
      "source": [
        "Matrix Addition in CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIYivnPlkjwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6443a2-e42c-49f6-ef71-630f19686ecd"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "__global__ void addKernel(int* c, const int* a, const int* b)\n",
        "{\n",
        "    int x = threadIdx.x;\n",
        "    int y = threadIdx.y;\n",
        "    int i = y * (blockDim.x) + x; // index = y * WIDTH + x\n",
        "    c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int WIDTH=5;\n",
        "    int a[WIDTH][WIDTH];\n",
        "    int b[WIDTH][WIDTH];\n",
        "    int c[WIDTH][WIDTH] = { 0 };\n",
        "\n",
        "    for (int y=0; y<WIDTH; y++){\n",
        "        for (int x=0; x<WIDTH; x++){\n",
        "            a[y][x] = y*10+x;\n",
        "            b[y][x] = (y*10+x)*100;\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    int *dev_a, *dev_b, *dev_c = 0; // GPU does not know the array structure of dev_a, dev_b, dev_c\n",
        "    cudaMalloc((void**)&dev_a, WIDTH*WIDTH*sizeof(int)); // Memory allocation (WIDTH*WIDTH)\n",
        "    cudaMalloc((void**)&dev_b, WIDTH*WIDTH*sizeof(int)); // Memory allocation (WIDTH*WIDTH)\n",
        "    cudaMalloc((void**)&dev_c, WIDTH*WIDTH*sizeof(int)); // Memory allocation (WIDTH*WIDTH)\n",
        "\n",
        "    cudaMemcpy(dev_a, a, WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 DimBlock(WIDTH,WIDTH);\n",
        "    addKernel <<<1,DimBlock>>>(dev_c,dev_a,dev_b);\n",
        "\n",
        "    cudaMemcpy(c, dev_c, WIDTH*WIDTH*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    for (int y=0; y<WIDTH; y++){\n",
        "        for (int x=0; x<WIDTH; x++){\n",
        "            printf(\"%5d \", c[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0   101   202   303   404 \n",
            " 1010  1111  1212  1313  1414 \n",
            " 2020  2121  2222  2323  2424 \n",
            " 3030  3131  3232  3333  3434 \n",
            " 4040  4141  4242  4343  4444 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsRExb8zCAbD"
      },
      "source": [
        "Matrix Multiplication in Host (CPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ML2q-wp7aEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bebb82e-5c4a-4891-c077-c847590f26fd"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int WIDTH=5;\n",
        "    int a[WIDTH][WIDTH];\n",
        "    int b[WIDTH][WIDTH];\n",
        "    int c[WIDTH][WIDTH] = { 0 };\n",
        "\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            a[y][x] = y+x;\n",
        "            b[y][x] = y+x;\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            int sum=0;\n",
        "            for (int k=0; k<WIDTH; k++)\n",
        "            {\n",
        "                sum += a[y][k] * b[k][x];\n",
        "            }\n",
        "            c[y][x] = sum;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"--------Matrix A---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", a[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    \n",
        "    printf(\"--------Matrix B---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", b[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"--------Matrix C---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", c[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------Matrix A---------\n",
            "    0     1     2     3     4 \n",
            "    1     2     3     4     5 \n",
            "    2     3     4     5     6 \n",
            "    3     4     5     6     7 \n",
            "    4     5     6     7     8 \n",
            "--------Matrix B---------\n",
            "    0     1     2     3     4 \n",
            "    1     2     3     4     5 \n",
            "    2     3     4     5     6 \n",
            "    3     4     5     6     7 \n",
            "    4     5     6     7     8 \n",
            "--------Matrix C---------\n",
            "   30    40    50    60    70 \n",
            "   40    55    70    85   100 \n",
            "   50    70    90   110   130 \n",
            "   60    85   110   135   160 \n",
            "   70   100   130   160   190 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbQBF0ZnEDKo"
      },
      "source": [
        "Matrix Multiplication in Host (GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0w_KG79DNz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d0d303-23ae-405f-e7b9-912f94b52724"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void multiply(int* c, const int* a, const int* b, const int WIDTH)\n",
        "{\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int i = y * WIDTH + x;\n",
        "    \n",
        "    int sum=0;\n",
        "    for (int k=0; k<WIDTH; k++)\n",
        "    {\n",
        "      sum += a[y*WIDTH+k] * b[k*WIDTH+x];\n",
        "    }\n",
        "    c[i] = sum;\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int WIDTH=5;\n",
        "    int a[WIDTH][WIDTH];\n",
        "    int b[WIDTH][WIDTH];\n",
        "    int c[WIDTH][WIDTH] = { 0 };\n",
        "\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            a[y][x] = y+x;\n",
        "            b[y][x] = y+x;\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    int *dev_a, *dev_b, *dev_c = 0;\n",
        "    cudaMalloc((void**)&dev_a,WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b,WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c,WIDTH*WIDTH*sizeof(int));\n",
        " \n",
        "    cudaMemcpy(dev_a, a ,WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b ,WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        " \n",
        "    dim3 DimBlock(5,5);\n",
        " \n",
        "    multiply<<<1,DimBlock>>>(dev_c, dev_a, dev_b, WIDTH);\n",
        " \n",
        "    cudaMemcpy(c, dev_c,WIDTH*WIDTH*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"--------Matrix A---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", a[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    \n",
        "    printf(\"--------Matrix B---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", b[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"--------Matrix C---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", c[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        " \n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------Matrix A---------\n",
            "    0     1     2     3     4 \n",
            "    1     2     3     4     5 \n",
            "    2     3     4     5     6 \n",
            "    3     4     5     6     7 \n",
            "    4     5     6     7     8 \n",
            "--------Matrix B---------\n",
            "    0     1     2     3     4 \n",
            "    1     2     3     4     5 \n",
            "    2     3     4     5     6 \n",
            "    3     4     5     6     7 \n",
            "    4     5     6     7     8 \n",
            "--------Matrix C---------\n",
            "   30    40    50    60    70 \n",
            "   40    55    70    85   100 \n",
            "   50    70    90   110   130 \n",
            "   60    85   110   135   160 \n",
            "   70   100   130   160   190 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSbOs_kJi2qr"
      },
      "source": [
        "Kernel Launch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbGZ1wuPGnFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a577a7b1-7ea3-41fc-fe26-c4c5606cb3d4"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void multiply(int* c, const int* a, const int* b, const int WIDTH)\n",
        "{\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int i = y * WIDTH + x;\n",
        "    \n",
        "    int sum=0;\n",
        "    for (int k=0; k<WIDTH; k++)\n",
        "    {\n",
        "      sum += a[y*WIDTH+k] * b[k*WIDTH+x];\n",
        "    }\n",
        "    c[i] = sum;\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int WIDTH = 8;\n",
        "    const int TILE_WIDTH = 2;\n",
        "    int a[WIDTH][WIDTH];\n",
        "    int b[WIDTH][WIDTH];\n",
        "    int c[WIDTH][WIDTH] = { 0 };\n",
        "\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            a[y][x] = y+x;\n",
        "            b[y][x] = y+x;\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    int *dev_a, *dev_b, *dev_c = 0;\n",
        "    cudaMalloc((void**)&dev_a,WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b,WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c,WIDTH*WIDTH*sizeof(int));\n",
        " \n",
        "    cudaMemcpy(dev_a, a ,WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b ,WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        " \n",
        "    dim3 dimGrid(WIDTH/TILE_WIDTH,WIDTH/TILE_WIDTH,1);\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n",
        " \n",
        "    multiply<<<dimGrid,dimBlock>>>(dev_c, dev_a, dev_b, WIDTH);\n",
        " \n",
        "    cudaMemcpy(c, dev_c,WIDTH*WIDTH*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"--------Matrix A---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", a[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    \n",
        "    printf(\"--------Matrix B---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", b[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"--------Matrix C---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++)\n",
        "    {\n",
        "        for (int x=0; x<WIDTH; x++)\n",
        "        {\n",
        "            printf(\"%5d \", c[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        " \n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------Matrix A---------\n",
            "    0     1     2     3     4     5     6     7 \n",
            "    1     2     3     4     5     6     7     8 \n",
            "    2     3     4     5     6     7     8     9 \n",
            "    3     4     5     6     7     8     9    10 \n",
            "    4     5     6     7     8     9    10    11 \n",
            "    5     6     7     8     9    10    11    12 \n",
            "    6     7     8     9    10    11    12    13 \n",
            "    7     8     9    10    11    12    13    14 \n",
            "--------Matrix B---------\n",
            "    0     1     2     3     4     5     6     7 \n",
            "    1     2     3     4     5     6     7     8 \n",
            "    2     3     4     5     6     7     8     9 \n",
            "    3     4     5     6     7     8     9    10 \n",
            "    4     5     6     7     8     9    10    11 \n",
            "    5     6     7     8     9    10    11    12 \n",
            "    6     7     8     9    10    11    12    13 \n",
            "    7     8     9    10    11    12    13    14 \n",
            "--------Matrix C---------\n",
            "  140   168   196   224   252   280   308   336 \n",
            "  168   204   240   276   312   348   384   420 \n",
            "  196   240   284   328   372   416   460   504 \n",
            "  224   276   328   380   432   484   536   588 \n",
            "  252   312   372   432   492   552   612   672 \n",
            "  280   348   416   484   552   620   688   756 \n",
            "  308   384   460   536   612   688   764   840 \n",
            "  336   420   504   588   672   756   840   924 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El7_lIK-CrvT"
      },
      "source": [
        "Host version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSHf6ixlCyH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b8fa4d-425d-4188-a085-83f8df3121ab"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define GRIDSIZE (8*1024) // 8K\n",
        "#define BLOCKSIZE 1024 // 1K\n",
        "#define TOTALSIZE (GRIDSIZE * BLOCKSIZE) // 32MB (8K * 1K * 4B)\n",
        "\n",
        "\n",
        "void genData(float* ptr, unsigned int size){\n",
        "    while (size--){\n",
        "        *ptr++ = (float)(rand() % 1000)/1000.0F;\n",
        "    }\n",
        "}\n",
        "\n",
        "void adjDiff(float* dst, const float* src, unsigned int size)\n",
        "{\n",
        "    for(int i = 1; i<size; ++i)\n",
        "    {\n",
        "        dst[i] = src[i] - src[i-1];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float* pSource = NULL;\n",
        "    float* pResult = NULL;\n",
        "\n",
        "    float* pSourceDev = NULL;\n",
        "    float* pResultDev = NULL;\n",
        "\n",
        "    int i;\n",
        "\n",
        "    pSource = (float*)malloc(TOTALSIZE * sizeof(float));\n",
        "    pResult = (float*)malloc(TOTALSIZE * sizeof(float));\n",
        "\n",
        "    genData(pSource, TOTALSIZE);\n",
        " \n",
        "    //start timer\n",
        "    std::chrono::system_clock::time_point start = std::chrono::system_clock::now();\n",
        "    // adjacent difference\n",
        "    adjDiff(pResult, pSource, TOTALSIZE);\n",
        "    //end timer\n",
        "    std::chrono::system_clock::time_point end = std::chrono::system_clock::now();\n",
        "    std::chrono::nanoseconds duration_nano = end - start;\n",
        "    cudaMemcpy(pResult, pResultDev, TOTALSIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    printf(\"Elapsed Time: %lld ns\\n\", duration_nano);\n",
        " \n",
        "    //print sample cases \n",
        "    i = 1;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "    i = TOTALSIZE - 1;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "    i = TOTALSIZE/2;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        " \n",
        "    free(pSource);\n",
        "    free(pResult);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed Time: 42622234 ns\n",
            "i=      1: 0.503000=0.886000-0.383000\n",
            "i=8388607: 0.700000=0.820000-0.120000\n",
            "i=4194304: 0.609000=0.917000-0.308000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb4Pd6_Y3hGL"
      },
      "source": [
        "Device version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhq4XxTjkNLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1b7540-1538-4d91-9ae1-11c4923d78af"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define GRIDSIZE (8*1024) // 8K\n",
        "#define BLOCKSIZE 1024 // 1K\n",
        "#define TOTALSIZE (GRIDSIZE * BLOCKSIZE) // 32MB (8K * 1K * 4B)\n",
        "\n",
        "void genData(float* ptr, unsigned int size){\n",
        "    while (size--){\n",
        "        *ptr++ = (float)(rand() % 1000)/1000.0F;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void adjDiff(float* result, float* input){\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i>0){\n",
        "        float x_i = input[i];\n",
        "        float x_i_m1 = input[i-1];\n",
        "        result[i] = x_i - x_i_m1;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float* pSource = NULL;\n",
        "    float* pResult = NULL;\n",
        "\n",
        "    float* pSourceDev = NULL;\n",
        "    float* pResultDev = NULL;\n",
        "\n",
        "    int i;\n",
        "\n",
        "    pSource = (float*)malloc(TOTALSIZE * sizeof(float));\n",
        "    pResult = (float*)malloc(TOTALSIZE * sizeof(float));\n",
        "\n",
        "    genData(pSource, TOTALSIZE);\n",
        "\n",
        "    pResult[0] = 0.0F;\n",
        "\n",
        "    cudaMalloc((void**)&pSourceDev, TOTALSIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&pResultDev, TOTALSIZE * sizeof(float));\n",
        "    cudaMemcpy(pSourceDev, pSource, TOTALSIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    \n",
        "    //start timer\n",
        "    std::chrono::system_clock::time_point start = std::chrono::system_clock::now();\n",
        "    // adjacent difference\n",
        "   \n",
        "    dim3 DimGrid(GRIDSIZE, 1, 1);\n",
        "    dim3 DimBlock(BLOCKSIZE, 1, 1);\n",
        "\n",
        "    adjDiff<<<DimGrid,DimBlock>>>(pResultDev,pSourceDev);\n",
        "\n",
        "    //end timer\n",
        "    std::chrono::system_clock::time_point end = std::chrono::system_clock::now();\n",
        "    std::chrono::nanoseconds duration_nano = end - start;\n",
        "    cudaMemcpy(pResult, pResultDev, TOTALSIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    printf(\"Elapsed Time: %lld ns\\n\", duration_nano);\n",
        "\n",
        "\n",
        "    //print sample cases \n",
        "    i = 1;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "    i = TOTALSIZE - 1;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "    i = TOTALSIZE/2;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "\n",
        "    free(pSource);\n",
        "    free(pResult);\n",
        "    cudaFree(pSourceDev);\n",
        "    cudaFree(pResultDev);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed Time: 22754 ns\n",
            "i=      1: 0.000000=0.886000-0.383000\n",
            "i=8388607: 0.000000=0.820000-0.120000\n",
            "i=4194304: 0.000000=0.917000-0.308000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj77CGtF3o5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7655fc2a-763b-4dfb-fe2c-24c4d2ce77ef"
      },
      "source": [
        "%cd /usr/local/cuda-11.0/samples/1_Utilities/deviceQuery/\n",
        "!make\n",
        "!ls\n",
        "!./deviceQuery"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-11.0/samples/1_Utilities/deviceQuery\n",
            "/usr/local/cuda-11.0/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o deviceQuery.o -c deviceQuery.cpp\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda-11.0/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o deviceQuery deviceQuery.o \n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n",
            "deviceQuery\t deviceQuery.o\tNsightEclipse.xml\n",
            "deviceQuery.cpp  Makefile\treadme.txt\n",
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          11.2 / 11.0\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.2, CUDA Runtime Version = 11.0, NumDevs = 1\n",
            "Result = PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YvmwNgcPo_n"
      },
      "source": [
        "AdjDiff Shared Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-uVdjjB5mCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a378da0b-1047-407f-fb74-c44a4f8674ff"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define GRIDSIZE (8*1024) // 8K\n",
        "#define BLOCKSIZE 1024 // 1K\n",
        "#define TOTALSIZE (GRIDSIZE * BLOCKSIZE) // 32MB (8K * 1K * 4B)\n",
        "\n",
        "void genData(float* ptr, unsigned int size){\n",
        "    while (size--){\n",
        "        *ptr++ = (float)(rand() % 1000)/1000.0F;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void adjDiff(float* result, float* input){\n",
        "    __shared__ float s_data[BLOCKSIZE];\n",
        "    unsigned int tx = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + tx;\n",
        "    s_data[tx] = input[i]; // global --> shared data movement \n",
        "    __syncthreads();\n",
        "    if (tx>0){\n",
        "        result[i] = s_data[tx] - s_data[tx-1];\n",
        "    } \n",
        "    else if(i>0){\n",
        "        result[i] = s_data[tx] - input[i-1];\n",
        "    }\n",
        "    __syncthreads();\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float* pSource = NULL;\n",
        "    float* pResult = NULL;\n",
        "\n",
        "    float* pSourceDev = NULL;\n",
        "    float* pResultDev = NULL;\n",
        "\n",
        "    int i;\n",
        "\n",
        "    pSource = (float*)malloc(TOTALSIZE * sizeof(float));\n",
        "    pResult = (float*)malloc(TOTALSIZE * sizeof(float));\n",
        "\n",
        "    genData(pSource, TOTALSIZE);\n",
        "\n",
        "    pResult[0] = 0.0F;\n",
        "\n",
        "    \n",
        "\n",
        "    cudaMalloc((void**)&pSourceDev, TOTALSIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&pResultDev, TOTALSIZE * sizeof(float));\n",
        "    cudaMemcpy(pSourceDev, pSource, TOTALSIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // adjacent difference\n",
        "    //adjDiff(pResult, pSource, TOTALSIZE);\n",
        "    dim3 DimGrid(GRIDSIZE, 1, 1);\n",
        "    dim3 DimBlock(BLOCKSIZE, 1, 1);\n",
        "\n",
        "    //start timer\n",
        "    std::chrono::system_clock::time_point start = std::chrono::system_clock::now();\n",
        "    adjDiff<<<DimGrid,DimBlock>>>(pResultDev,pSourceDev);\n",
        "\n",
        "    //end timer\n",
        "    std::chrono::system_clock::time_point end = std::chrono::system_clock::now();\n",
        "    std::chrono::nanoseconds duration_nano = end - start;\n",
        "\n",
        "    cudaMemcpy(pResult, pResultDev, TOTALSIZE * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Elapsed Time: %lld ns\\n\", duration_nano);\n",
        "\n",
        "\n",
        "    //print sample cases \n",
        "    i = 1;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "    i = TOTALSIZE - 1;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "    i = TOTALSIZE/2;\n",
        "    printf(\"i=%7d: %f=%f-%f\\n\", i, pResult[i], pSource[i], pSource[i-1]);\n",
        "\n",
        "    free(pSource);\n",
        "    free(pResult);\n",
        "    cudaFree(pSourceDev);\n",
        "    cudaFree(pResultDev);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed Time: 17994 ns\n",
            "i=      1: 0.503000=0.886000-0.383000\n",
            "i=8388607: 0.700000=0.820000-0.120000\n",
            "i=4194304: 0.609000=0.917000-0.308000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHcg3_11vNtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe03841d-e005-4970-a9b9-e607d7b4d225"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define WIDTH 512\n",
        "#define TILE_WIDTH 32\n",
        "\n",
        "__global__ void multiply(int* c, const int* a, const int* b){\n",
        "    __shared__ int ds_A[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_B[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int Row = blockIdx.y * TILE_WIDTH + threadIdx.y;\n",
        "    int Col = blockIdx.x * TILE_WIDTH + threadIdx.x;\n",
        "\n",
        "    int sub_C = 0;\n",
        "\n",
        "    for (int m=0; m < WIDTH/TILE_WIDTH; ++m){\n",
        "        ds_A[threadIdx.y][threadIdx.x] = a[Row*WIDTH + m*TILE_WIDTH+threadIdx.x];\n",
        "        ds_B[threadIdx.y][threadIdx.x] = b[(m*TILE_WIDTH+threadIdx.y)*WIDTH + Col];\n",
        "        __syncthreads();\n",
        "        for (int k=0; k<TILE_WIDTH; ++k){\n",
        "            sub_C += ds_A[threadIdx.y][k] * ds_B[k][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    c[Row*WIDTH+Col] = sub_C;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    //const int WIDTH=512;\n",
        "    //const int TILE_WIDTH=32;\n",
        "    int a[WIDTH][WIDTH];\n",
        "    int b[WIDTH][WIDTH];\n",
        "    int c[WIDTH][WIDTH] = { 0 };\n",
        "\n",
        "    for (int y=0; y<WIDTH; y++){\n",
        "        for (int x=0; x<WIDTH; x++){\n",
        "            a[y][x] = y;\n",
        "            b[y][x] = x;\n",
        "        }\n",
        "    }\n",
        "    int num_bytes = WIDTH*WIDTH*sizeof(int);\n",
        "\n",
        "    int *dev_a, *dev_b, *dev_c = 0;\n",
        "    cudaMalloc((void**)&dev_c, WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_a, WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, WIDTH*WIDTH*sizeof(int));\n",
        "\n",
        "    cudaMemcpy(dev_a, a, WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, WIDTH*WIDTH*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 DimGrid(WIDTH/TILE_WIDTH,WIDTH/TILE_WIDTH);\n",
        "    dim3 DimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "\n",
        "    //start timer\n",
        "    std::chrono::system_clock::time_point start = std::chrono::system_clock::now();\n",
        "\n",
        "    multiply<<<DimGrid,DimBlock>>>(dev_c, dev_a, dev_b);\n",
        "\n",
        "    //end timer\n",
        "    std::chrono::system_clock::time_point end = std::chrono::system_clock::now();\n",
        "    std::chrono::nanoseconds duration_nano = end - start;\n",
        "\n",
        "    printf(\"Elapsed Time: %lld ns\\n\", duration_nano);\n",
        "\n",
        "    cudaMemcpy(c, dev_c, WIDTH*WIDTH*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    //for (int y=0; y<WIDTH; y++){\n",
        "    //    for (int x=0; x<WIDTH; x++){\n",
        "    //        // Kernel\n",
        "    //    }\n",
        "    //}\n",
        "\n",
        "    /*\n",
        "    printf(\"--------Matrix A---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++){\n",
        "        for (int x=0; x<WIDTH; x++){\n",
        "            printf(\"%5d \", a[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    \n",
        "    printf(\"--------Matrix B---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++){\n",
        "        for (int x=0; x<WIDTH; x++){\n",
        "            printf(\"%5d \", b[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"--------Matrix C---------\\n\");\n",
        "    for (int y=0; y<WIDTH; y++){\n",
        "        for (int x=0; x<WIDTH; x++){\n",
        "            printf(\"%5d \", c[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    */\n",
        "    \n",
        "    //print the result\n",
        "\n",
        "    int i=0,j=0;\n",
        "    printf(\"c[%4d][%4d] = %d\\n\",i,j,c[i][j]);\n",
        "    i=WIDTH/2;\n",
        "    j=WIDTH/2;\n",
        "    printf(\"c[%4d][%4d] = %d\\n\",i,j,c[i][j]);\n",
        "    i=WIDTH-1;\n",
        "    j=WIDTH-1;\n",
        "    printf(\"c[%4d][%4d] = %d\\n\",i,j,c[i][j]);\n",
        "\n",
        "    cudaFree(dev_c);\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed Time: 15596 ns\n",
            "c[   0][   0] = 0\n",
            "c[ 256][ 256] = 33554432\n",
            "c[ 511][ 511] = 133693952\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}